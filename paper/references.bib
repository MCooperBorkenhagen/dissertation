@article{Kuperman2012,
abstract = {We present age-of-acquisition (AoA) ratings for 30,121 English content words (nouns, verbs, and adjectives). For data collection, this megastudy used the Web-based crowdsourcing technology offered by the Amazon Mechanical Turk. Our data indicate that the ratings collected in this way are as valid and reliable as those collected in laboratory conditions (the correlation between our ratings and those collected in the lab from U. S. students reached.93 for a subsample of 2,500 monosyllabic words). We also show that our AoA ratings explain a substantial percentage of the variance in the lexical-decision data of the English Lexicon Project, over and above the effects of log frequency, word length, and similarity to other words. This is true not only for the lemmas used in our rating study, but also for their inflected forms. We further discuss the relationships of AoA with other predictors of word recognition and illustrate the utility of AoA ratings for research on vocabulary growth. {\textcopyright} 2012 Psychonomic Society, Inc.},
author = {Kuperman, Victor and Stadthagen-Gonzalez, Hans and Brysbaert, Marc},
doi = {10.3758/s13428-012-0210-4},
file = {::},
isbn = {1342801202},
journal = {Behavior Research Methods},
keywords = {Age of acquisition,Amazon Mechanical Turk,Ratings,Word recognition},
number = {4},
pages = {978--990},
title = {{Age-of-acquisition ratings for 30,000 English words}},
volume = {44},
year = {2012}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
} 


@article{Harm2004,
abstract = {Are words read visually (by means of a direct mapping from orthography to semantics) or phonologically (by mapping from orthography to phonology to semantics)? The authors addressed this long-standing debate by examining how a large-scale computational model based on connectionist principles would solve the problem and comparing the model's performance to people's. In contrast to previous models, the present model uses an architecture in which meanings are jointly determined by the 2 components, with the division of labor between them affected by the nature of the mappings between codes. The model is consistent with a variety of behavioral phenomena, including the results of studies of homophones and pseudohomophones thought to support other theories, and illustrates how efficient processing can be achieved using multiple simultaneous constraints.},
author = {Harm, Michael W. and Seidenberg, Mark S.},
doi = {10.1037/0033-295X.111.3.662},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harm, Seidenberg - 2004 - Computing the meanings of words in reading Cooperative division of labor between visual and phonological pr(2).pdf:pdf},
issn = {0033295X},
journal = {Psychological Review},
number = {3},
pages = {662--720},
pmid = {15250780},
title = {{Computing the meanings of words in reading: Cooperative division of labor between visual and phonological processes}},
volume = {111},
year = {2004}
}


@article{Perry2010,
abstract = {Most words in English have more than one syllable, yet the most influential computational models of reading aloud are restricted to processing monosyllabic words. Here, we present CDP++, a new version of the Connectionist Dual Process model (Perry, Ziegler, & Zorzi, 2007). CDP++ is able to simulate the reading aloud of mono- and disyllabic words and nonwords, and learns to assign stress in exactly the same way as it learns to associate graphemes with phonemes. CDP++ is able to simulate the monosyllabic benchmark effects its predecessor could, and therefore shows full backwards compatibility. CDP++ also accounts for a number of novel effects specific to disyllabic words, including the effects of stress regularity and syllable number. In terms of database performance, CDP++ accounts for over 49% of the reaction time variance on items selected from the English Lexicon Project, a very large database of several thousand of words. With its lexicon of over 32,000 words, CDP++ is therefore a notable example of the successful scaling-up of a connectionist model to a size that more realistically approximates the human lexical system. {\textcopyright} 2010 Elsevier Inc.},
author = {Perry, Conrad and Ziegler, Johannes C. and Zorzi, Marco},
doi = {10.1016/j.cogpsych.2010.04.001},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perry, Ziegler, Zorzi - 2010 - Beyond single syllables Large-scale modeling of reading aloud with the Connectionist Dual Process (CDP) m.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {Computational modeling,Disyllables,Reading aloud,Word stress},
number = {2},
pages = {106--151},
publisher = {Elsevier Inc.},
title = {{Beyond single syllables: Large-scale modeling of reading aloud with the Connectionist Dual Process (CDP++) model}},
url = {http://dx.doi.org/10.1016/j.cogpsych.2010.04.001},
volume = {61},
year = {2010}
}


@article{Perry2019,
abstract = {Learning to read is foundational for literacy development, yet many children in primary school fail to become efficient readers despite normal intelligence and schooling. This condition, referred to as developmental dyslexia, has been hypothesized to occur because of deficits in vision, attention, auditory and temporal processes, and phonology and language. Here, we used a developmentally plausible computational model of reading acquisition to investigate how the core deficits of dyslexia determined individual learning outcomes for 622 children (388 with dyslexia). We found that individual learning trajectories could be simulated on the basis of three component skills related to orthography, phonology, and vocabulary. In contrast, single-deficit models captured the means but not the distribution of reading scores, and a model with noise added to all representations could not even capture the means. These results show that heterogeneity and individual differences in dyslexia profiles can be simulated only ...},
author = {Perry, Conrad and Zorzi, Marco and Ziegler, Johannes C.},
doi = {10.1177/0956797618823540},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perry, Zorzi, Ziegler - 2019 - Understanding Dyslexia Through Personalized Large-Scale Computational Models.pdf:pdf},
journal = {Psychological Science},
keywords = {computer simulation,dyslexia,reading},
number = {3},
pages = {386--395},
title = {{Understanding Dyslexia Through Personalized Large-Scale Computational Models}},
volume = {30},
year = {2019}
}


@article{Plaut1996,
abstract = {A connectionist approach to processing in quasi-regular domains, as exemplified by English word reading, is developed. Networks using appropriately structured orthographic and phonological representations were trained to read both regular and exception words, and yet were also able to read pronounceable nonwords as well as skilled readers. A mathematical analysis of a simplified system clarifies the close relationship of word frequency and spelling-sound consistency in influencing naming latencies. These insights were verified in subsequent simulations, including an attractor network that accounted for latency data directly in its time to settle on a response. Further analyses of the ability of networks to reproduce data on acquired surface dyslexia support a view of the reading system that incorporates a graded division of labor between semantic and phonological processes, and contrasts in important ways with the standard dual-route account.},
author = {Plaut, David C. and McClelland, James L. and Seidenberg, Mark S. and Patterson, Karalyn},
doi = {10.1037/0033-295X.103.1.56},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Plaut et al. - 1996 - Understanding Normal and Impaired Word Reading Computational Principles in Quasi-Regular Domains.pdf:pdf},
journal = {Psychological Review},
number = {1},
pages = {56--115},
pmid = {8650300},
title = {{Understanding Normal and Impaired Word Reading: Computational Principles in Quasi-Regular Domains}},
volume = {103},
year = {1996}
}


@article{Rogers2004,
abstract = {Wernieke (1900, as cited in G. H. Eggert, 1977) suggested that semantic knowledge arises from the interaction of perceptual representations of objects and words. The authors present a parallel distributed processing implementation of this theory, in which semantic representations emerge from mechanisms that acquire the mappings between visual representations of objects and their verbal descriptions. To test the theory, they trained the model to associate names, verbal descriptions, and visual representations of objects. When its inputs and outputs are constructed to capture aspects of structure apparent in attribute-norming experiments, the model provides an intuitive account of semantic task performance. The authors then used the model to understand the structure of impaired performance in patients with selective and progressive impairments of conceptual knowledge. Data from 4 well-known semantic tasks revealed consistent patterns that find a ready explanation in the model. The relationship between the model and related theories of semantic representation is discussed.},
author = {Rogers, Timothy T. and {Lambon Ralph}, Matthew A. and Garrard, Peter and Bozeat, Sasha and McClelland, James L. and Hodges, John R. and Patterson, Karalyn},
doi = {10.1037/0033-295X.111.1.205},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rogers et al. - 2004 - Structure and Deterioration of Semantic Memory A Neuropsychological and Computational Investigation.pdf:pdf},
journal = {Psychological Review},
number = {1},
pages = {205--235},
title = {{Structure and Deterioration of Semantic Memory: A Neuropsychological and Computational Investigation}},
volume = {111},
year = {2004}
}

@article{Sibley2010,
author = {Sibley, Daragh E. and Kello, Christopher T. and Seidenberg, Mark S.},
doi = {10.1080/09541440903080583},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sibley, Kello, Seidenberg - 2010 - Learning Orthographic and Phonological Representations in Models of Monosyllabic and Bisyllabic Namin.pdf:pdf},
journal = {European Journal of Cognitive Psychology},
keywords = {icle},
number = {5},
pages = {650--668},
title = {{Learning Orthographic and Phonological Representations in Models of Monosyllabic and Bisyllabic Naming}},
volume = {22},
year = {2010}
}


@article{Elman1990,
author = {Elman, Jeffrey L.},
doi = {10.1207/s15516709cog1402_1},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elman - 1990 - Finding Structure in Time.pdf:pdf},
isbn = {1551-6709},
journal = {Cognitive science},
number = {2},
pages = {179--211},
pmid = {19563812},
title = {{Finding Structure in Time}},
volume = {14},
year = {1990}
}

@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hochreiter, Schmidhuber - 1997 - Long Short-Term Memory.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
pmid = {9377276},
title = {{Long Short-Term Memory}},
volume = {9},
year = {1997}
}

@article{Kawamoto2015,
abstract = {Speech production and reading aloud studies have much in common, especially the last stages involved in producing a response. We focus on the minimal planning unit (MPU) in articulation. Although most researchers now assume that the MPU is the syllable, we argue that it is at least as small as the segment based on negative response latencies (i.e., response initiation before presentation of the complete target) and longer initial segment durations in a reading aloud task where the initial segment is primed. We also discuss why such evidence was not found in earlier studies. Next, we rebut arguments that the segment cannot be the MPU by appealing to flexible planning scope whereby planning units of different sizes can be used due to individual differences, as well as stimulus and experimental design differences. We also discuss why negative response latencies do not arise in some situations and why anticipatory coarticulation does not preclude the segment MPU. Finally, we argue that the segment MPU is also important because it provides an alternative explanation of results implicated in the serial vs. parallel processing debate.},
author = {Kawamoto, Alan H. and Liu, Qiang and Kello, Christopher T.},
doi = {10.3389/fpsyg.2015.01457},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kawamoto, Liu, Kello - 2015 - The segment as the minimal planning unit in speech production and reading aloud Evidence and implications.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Absolute latency,Segment duration,Serial vs. parallel encoding},
number = {September},
pages = {1--6},
title = {{The segment as the minimal planning unit in speech production and reading aloud: Evidence and implications}},
volume = {6},
year = {2015}
}

@article{Chang2019,
abstract = {Diversity of vocabulary knowledge and quantity of language exposure prior to literacy are key predictors of reading development. However, diversity and quantity of exposure are difficult to distinguish in behavioural studies, and so the causal relations with literacy are not well known. We tested these relations by training a connectionist triangle model of reading that learned to map between semantic; phonological; and, later, orthographic forms of words. The model first learned to map between phonology and semantics, where we manipulated the quantity and diversity of this preliterate language experience. Then the model learned to read. Both diversity and quantity of exposure had unique effects on reading performance, with larger effects for written word comprehension than for reading fluency. The results further showed that quantity of preliteracy language exposure was beneficial only when this was to a varied vocabulary and could be an impediment when exposed to a limited vocabulary. [ABSTRACT FROM AUTHOR]},
author = {Chang, Ya-Ning and Monaghan, Padraic},
doi = {10.1080/10888438.2018.1529177},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang, Monaghan - 2019 - Quantity and Diversity of Preliteracy Language Exposure Both Affect Literacy Development Evidence from a Comput.pdf:pdf},
journal = {Scientific Studies of Reading},
number = {3},
pages = {235--253},
publisher = {Routledge},
title = {{Quantity and Diversity of Preliteracy Language Exposure Both Affect Literacy Development: Evidence from a Computational Model of Reading}},
url = {https://doi.org/10.1080/10888438.2018.1529177},
volume = {23},
year = {2019}
}

@inproceedings{Cox2019,
author = {Cox, Christopher R. and Borkenhagen, Matthew Cooper and Seidenberg, Mark S},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cox, Borkenhagen, Seidenberg - 2019 - Efficiency of learning in experience-limited domains Generalization beyond the WUG test.pdf:pdf},
keywords = {Computational modeling,efficient learning,generalization,human and machine learning,reading},
pages = {1566--1571},
title = {{Efficiency of learning in experience-limited domains: Generalization beyond the WUG test}},
year = {2019}
}


@article{Seidenberg1989,
abstract = {A parallel distributed processing model of visual word recognition and pronunciation is described. The model consists of sets of orthographic and phonological units and an interlevel of hidden units. Weights on connections between units were modified during a training phase using the back-propagation learning algorithm. The model simulates many aspects of human performance, including (a) differences between words in terms of processing difficulty, (b) pronunciation of novel items, (c) differences between readers in terms of word recognition skill, (d) transitions from beginning to skilled reading, and (e) differences in performance on lexical decision and naming tasks. The model's behavior early in the learning phase corresponds to that of children acquiring word recognition skills. Training with a smaller number of hidden units produces output characteristic of many dyslexic readers. Naming is simulated without pronunciation rules, and lexical decisions are simulated without accessing word-level representations. The performance of the model is largely determined by three factors: the nature of the input, a significant fragment of written English; the learning rule, which encodes the implicit structure of the orthography in the weights on connections; and the architecture of the system, which influences the scope of what can be learned.},
author = {Seidenberg, Mark S. and McClelland, James L.},
doi = {10.1037//0033-295X.96.4.523},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seidenberg, McClelland - 1989 - A Distributed, Developmental Model of Word Recognition and Naming.pdf:pdf},
journal = {Psychological Review},
number = {4},
pages = {523--568},
pmid = {2798649},
title = {{A Distributed, Developmental Model of Word Recognition and Naming}},
volume = {96},
year = {1989}
}

@article{Seidenberg2018,
abstract = {This article reviews the important role of statistical learning for language and reading development. Although statistical learning—the unconscious encoding of patterns in language input—has become widely known as a force in infants' early interpretation of speech, the role of this kind of learning for language and reading comprehension in children has received less attention. In fact, the implicit learning of co-occurrences of words, sentence structures, and other components of language forms a critical part of children's language comprehension and fluent reading. Beyond introducing basic information about language statistics, the article offers a discussion of how variability in the amount and nature of language experience can affect language development and literacy, including variation owing to the amount of language input in the child's linguistic environment and the variable nature of input for children who are exposed to multiple languages or multiple dialects.},
author = {Seidenberg, Mark S. and MacDonald, Maryellen C.},
doi = {10.1097/TLD.0000000000000144},
file = {:home/mcb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seidenberg, MacDonald - 2018 - The Impact of Language Experience on Language and Reading A Statistical Learning Approach.pdf:pdf},
isbn = {0000000000000},
journal = {Topics in Language Disorders},
keywords = {Bilingualism,Dialect,Individual differences,Language variation,Statistical learning,Vocabulary},
number = {1},
pages = {66--83},
title = {{The Impact of Language Experience on Language and Reading: A Statistical Learning Approach}},
volume = {38},
year = {2018}
}


