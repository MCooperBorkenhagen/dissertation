---
title: "Chapter 2. History"
output: html_document
---


# Chapter 2: A Brief History of Models of Word Reading

## Representational units

## Models of multisyllabic word reading
The CDP++ model from Perry et al. (2010) posits a complex architecture with subcompnents that capture different aspects of the theory from which the computational architecture is based. Said differently, their system lacks architectural homogeneity, a hallmark of connectionist learning systems. Some assumptions of the system violate primitives of learning seen in naturalistic environments. For example, CDP++ requires the prespecification of a graphemic level of representation, based on the assumption that letter sequences map cleanly onto phonemic sequences, and that such representational units contribute to low level operations within the reading system. Graphemes are identified on the input layer based on their frequency,  This violates an important aspect of development of word reading knowledge in that such representations (i.e., the ways that print sequences relate to auditory sequences) are learned and do not preexist in the learner once knowledge about print begins to develop.

In a connectionist architecture something like a grapheme may well exist, but it is an emergent aspect of the knowledge of the system that develops as the result of the exposure of the learning architecture to the environment.

The selection of representational units is a critical issue of theoretical interest in the development of a learning architecture that learns to read words. A fundamental question will always be: how do such representational units arise in learning? This issue plays even larger in models of word reading that deal in long words given that the longer the words are the more representational units there are to account for. In symbolic approaches this has been taken up historically as an issue of positing rules of identification, as in Rastle and Coltheart (2000). These rules take the form of complex verbal descriptions that specify structured labels for representational units based on the presence or absence of structural elements in a printed or spoken wordform.


## Statistical learning



# Survey of previous architectures

## Simple recurrent networks
The most comprehensive application of an SRN to date is Sibley et al. (2010), which used a two-component architecture for orthography and phonology, each with an SRN operating under the hood.

The most recent of these architectures can be found in @Luthra2020, which they refer to as VOISeR. This model of orthography-to-phonology processing takes in an orthographic sequence (a spatially represented)



## "Serial" effects in naming
The evidence most commonly taken to suggest that there is some type of serial processing operating during naming, particularly for words that contain "irregular" pronunciations, concerns the timecourse of naming processes for such words. 

Such findings are typically identified as evidence for a dual-route process operating during reading. The dual-route theory predicts that 


## Strategic control
There have been a number of studies concerning so-called "extra-stimulus" factors that concern processes in naming (see @kello2003 for a review), which have been described broadly as strategies for cognitive control in word naming. The most important of these for the present work has to do with the time-course of processing printed words.

In behavioral research on aspects of control in word reading, the method of control is typically manipulated by providing special instructions to the participant, or constructing a paradigm to elicit a control-type mechanism when processing a visually presented word. Most research on this topic and using experimental paradigms along these lines has concerned short, or monosyllabic words. This isn't surprising given the rich history of such words in theories of word recognition (discussed elsewhere here), and that characteristics of the stimuli have driven theorizing and experimentation; monosyllabic words offer natural constraints to theory building that are useful to the endeavor, and provide simplifying case-studies of most critical characteristics observed in words more broadly (see @yap2009 for discussion).


# Behavioral data
There are a number of possibilities for the visual span over which visual information is passed in the process of initiating phonology in word reading.



Earlier connectionist models avoided this issue in favor of simplified feedforward networks that typically passed visual information to phonology in a single temporal step. Alternative implementations using recurrent backpropagation through time were also used (ref.) These networks function with a continuous, recurrent component, over temporal intervals ("ticks" in that literature) where the input pattern (in a feedforward network) is allowed to stay clamped to the input layer, allowing for gradual buildup of the input signal over some time period. During training, error signal is backpropagated over timesteps where inputs are gradually being increased up to their eventual full activation state. However, architectures with recurrent backpropagation along these lines are simulating the timecourse of activation in a way that is different than networks that take time-distributed input patterns, like LSTM architectures and, more specifically, the architecture laid out in the current work.  Rather than simulating the ways that sequentially-arranged portions of perceptual information play in cross-modal mappings (where the perceptual information unfolds in a time-distributed manner), these earlier implementations of continuous processes that operate over some time were developed in order to understand the types of disordered behavior seen, for example, in patients with brain injuries that impact lexical or semantic processing (@Plaut1996, @Rogers2004). 


