


## Dispersion
Sequential approaches to orthography-to-phonology conversion solve this problem by processing discrete speech segments from discrete print segments in a left-to-right, segment-by-segment manner. These solutions always involve some form of justification (sometimes called "alignment" in the literature), though the alignment procedure differs across sequential implementations. For example, @Sejnowski1987 provided orthographic input strings as sequences of letters and mapped them to equal-length sequences of phonemes. This allowed their network to implement a kind of temporal processing over visual and its corresponding spoken pattern, but required architectural specifications that deviate from assumptions about processing in other connectionist networks. Their procedure required inserting null elements in slots where a phoneme wasn't present for the corresponding input letter (or grapheme) given that the input and output sequences were always equal length. So, for the input pattern `r scaps('late')` the corresponding output would be `L - EY - T - __`, with the final phoneme segment `__` being the null one given the word-final silent `r scaps('a')` in `r scaps('late')`. This avoids the type of dispersion found in feedforward networks, where knowledge about letters and their corresponding sounds is localized to weighted connections associated with specific slots given the way that input and output patterns are specified during learning, but introduces a different type of knowledge localization that is undesirable: that letters on the input layer become associated too narrowly with phonemic segments on the output given the segment-by-segment processing mechanism (i.e., they lose the context sensitive nature of processing due to the segment-by-segment way that print and speech are associated in the network).

Dual-route models use an assembly method, where a letter or letter segment (e.g., grapheme) is associated with a phonemic segment by assembly rule, where "assembly" in this literature refers to the association of phonological segments to its corresponding orthographic segment. Processing speech from print involves assembling the phonology from the pre-specified letter-sound rules, which are derived via an analytic technique that resides outside the scope of the computational architecture itself (i.e, specified by the experimenter). The assembly process happens alongside a lexical lookup procedure, which has its own separate timecourse. The relative timecourse of these processes determine whether a word is produced via assembly rules or as a structured lexical object. This is the extreme end of the spectrum of methods that result in knowledge dispersion. Here knowledge about the relationship between visual and spoken elements is dispersed across the symbolic rules that operate over the crossmodal assembly that takes place during learning and performance. This form of knowledge dispersion is different implementationally but related conceptually in that what is known about similar elements in the domain becomes dissociated based on the structure of the architecture, which of course has implications on the learning that takes place given that architecture.

Other approaches handle input strings with the use of slots, but in a different way than in @Sejnowski1987. Commonly in connectionist feedforward implementations input patterns are justified in a vowel-centered way (see @Plaut1996 for a discussion). A similar solution exists in hybrid connectionist/ dual route architectures like @Perry2010. Here the input patterns are fit into a template defined by structure in terms of orthography across syllables, which is specified by the limits of the structure of the training set. So, for example the template used for the two syllable template in @Perry2010 involves fitting orthographic inputs into a `CCCVCCCC` pattern on each of the two (possible) syllables via a "graphemic buffer". This is the mechanism that defines the "slots" on the visual input to which any given input pattern are aligned to the available phonemes.

In the present computational system there is no alignment, justification, or slots. However, an important question concerns whether or not knowledge is dispersed in a model specified in this way. The most direct comparison is to models that contain weighted connections between input and output units, and intermediary hidden ones too. The issue of dispersion is investigated in the present architecture in two ways. First, we present data about the extent to which identical input patterns in different (orthographic) contexts are associated with different units in the network and, second, the extent to which the overall pattern of representation of identical input patterns are similar to each other.

A further piece of supporting data concerns a manipulation to the masking mechanism used in the model. Masking introduces a kind of justification, but one where masked segments should never be realized in the knowledge of the learner.



