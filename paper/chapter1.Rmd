---
title: "introduction"
output: html_document
---

# Chapter 1: Introduction

Words are read by virtue of perceptual and cognitive processes that are distributed across space and time. As a reader engages visually with a word printed on the page, the reader's eyes move across portions of printed word, tapping her or his knowledge of speech, print, and meaning. Historically, cognitive accounts of word reading have been focused on the simplest of words of English - those with one syllable [@Perry2010; @Rastle2000; @Sibley2010; @Yap2009]. Models of monosyllabic word reading have been especially dominant in the connectionist learning literature (e.g., @Plaut1996; @Seidenberg1989), though preliminary implementations of recurrent networks that are capable of processing longer words have been put forward [@Sibley2008; @Sibley2010], but this work is young.

The focus on short words results from two primary factors. First, any model of word reading must at the very least account for the development of knowledge of the simplest words in the language given that short words tend to be learned earlier than long ones. Second, accounting for words that are longer than one syllable requires computational architecture that accounts for time-varying aspects of processing that occur over longer words, but can be avoided when studying shorter ones. This includes but is not limited to variability in prosodic information involved in pronunciation over different syllables (especially of vowels and their associated patterns of stress).

This dissertation reports on a model of word reading that associates print to speech, and that can accommodate words not bounded by orthographic or phonological length - that is, of words that are not limited to a single syllable. This model incorporates a number of standard assumptions about the characteristics of word reading^[These assumptions were adopted and extended from those articulated in @Plaut1996. See also the description of GRAIN networks in @McClelland1993 for related characteristics of similar information processing systems to this one.]:

* Learning happens over distributed representations of letters and sounds, where such representations convey featural information about their corresponding visual and articulatory structure
* Representational information comes to be encoded in patterns of activity on units in the system's architecture
* These patterns of activity encode graded knowledge about the elements of learning (words) and their myriad substructure
* Learning about visual and phonological features, and their covariation, happens gradually over the course of learning

Additionally, this work extends previous computational models of word reading by developing a model with the following characteristics:

1. Sequential dependencies within items (i.e., letters, sounds) are encoded by time-sensitive processes captured by the model.
2. Letters and sounds are represented veridically. Each letter and phoneme is represented with a representation that captures something about its unique (distributed) structure relative to all other letters and phonemes.
3. Knowledge about letters and phonemes are not bound by their slots within items during learning.
4. Learning that happens over the time-varying print and speech sequences are integrated within a single learning system, where activation within and across layers of the network is mutually constraining.

The remaining chapters of this dissertation are organized in the following way. First, in the remaining portion of Chapter 1, I will introduce the central issues in word reading as they relate to the type of sequential processing that is essential to the theory developed in the dissertation. Additionally, a brief history of models of word recognition will be provided. Chapter 2 describes the model architecture, highlighting the features that make it distinct from other previous architectures. Chapter 3 describes a range of human behavioral phenomena captured by the model, thus validating the architecture. Chapter 4 is a general discussion, addressing lingering issues with the model described and framing the dissertation in a broader theoretical landscape of human learning, and discussing future directions.

# Introduction
Language comes and goes in a time-contingent fashion. The language that we see and hear is structured in large part by sequential statistics that are learned through cognitive processes that happen across time. Letters are processed visually according to patterns of fixation that occur in a temporally governed manner, and auditory processes take place relative to sound patterns that appear in a fast fading way over time - among others. As a result, our theoretical models should account for the fact that such processing takes place in a sequentially arranged, time-contingent manner. Theories of reading are no exception given the range of temporal processes that operate in developing the skill.

Prevailing models of word reading have dealt with temporal aspects of processing in a few ways. Several influential models have used attractor networks that allow for a pattern of activation to settle into a stable state using recurrent dynamics [@Harm2004; @Plaut1996] when simulating learning and performance for monosyllabic words (mapping a spatially-fixed pattern of print to a spatially-fixed pattern of phonology). These models allow for the state of the system to change over time as a result of experience with a single learning event (like a word). The temporal dynamics and their effects under disorder have been important in understanding especially the results of injury to the cognitive system, where basins of attraction that develop through the recurrent dynamics of the system show behavior similar to brain-injured patients whose learning and performance they simulate (see @Plaut1991 for an example, and @Seidenberg2017 for a thorough discussion related to reading behavior).

In a related but underdeveloped line of work, simple recurrent networks (SRNs; see @Elman1990) have been applied to learning letter and phoneme sequences [@Sibley2008; @Sibley2010]. In their most simple form when applied to word learning, simple recurrent networks allow for the encoding of variable length sequences (like printed or spoken words) into a fixed length pattern. This is made possible through a network that passes the elements of a given sequence through a time-varying network, where a set of weighted connections is used to process elements of the sequence, one element at a time. Despite the proximal (one timestep at a time) way that error updates occur, the weighted connections come to encode information about more distal elements as well. The models in @Sibley2008 perform this task for letters and phonemes separately, where offline processing allows the output pattern for a given item of print to then be associated using a second SRN with a time-varying sequence of phonemes that corresponds to that print item. The networks in @Sibley2008 and @Sibley2010 used different recurrent layers for orthography and phonology, using the autoencoded vectors of the orthographic network as training patterns for phonological network. While important aspects of the implementation aren't clear from the reporting on the model ^[For example, the featural representations for orthography aren't described, including whether or not padded/ justified representations were used. More needs to be known about the nature of an SRN-based approach to an orthography-phonology reading model in order to make a more full assessment of its viability and theoretical value. To this end, the work of this dissertation is intended to be an extension of the @Sibley2010 model.], the way that it incorporates temporal processing on orthography and phonology seems intuitive. Letters are processed sequentially, as are phonemes.

Finally, some models have implemented a component of the architecture dedicated to model temporal aspects of naming in an implicit way, typically in the form of stress of syllables [@Perry2010; @Perry2019]. The best example of this comes from "connectionist dual-process models" [@Perry2010], which encode information about temporal dimensions of words (like the primary-secondary stress pattern in the word `r scaps('thankful')`) but in a non-temporal way. In the @Perry2010 model orthographic patterns are assigned to slots and then stress is applied via stress nodes based on the orthographic slots that the letters come to occupy in a two-layer feedforward network, developed in @Zorzi1998. There is a secondary component that handles stress on words that are stored in the lexical route, allowing for words to contain stress even if they aren't generated via the orthography-phonology network. This approach simulates temporal processes by non-temporal means by treating time-varying aspects of words as applying over spatial representations of the letters and sounds associated with the word. This method is similar to @Seva2009 which showed that a feedforward architecture can map a word's orthographic representation directly to its corresponding pattern of stress without recurrent processes operating in the network, with the @Perry2010 and related CDP models doing so in the context of a larger model framework that did more than apply stress rules.

This dissertation introduces novel aspects of a computational architecture that incorporate time into the reading system in explicit, psychologically plausible ways. This includes using recurrence in orthographic and phonological portions of the network using more current computational mechanisms for simulating time [@Hochreiter1997a; @Hochreiter1997b], featural information about stress encoded on phonological segments (namely vowels), and model organization that allows time-varying orthographic information to mix with phonological processing within a single, homogeneous computational architecture.

# Computational models of word reading: A brief history
Recognizing and naming printed words is an important important phenomenon with longstanding attention in cognitive science and related disciplines [@Adams1991; @Snowling2005; @Seidenberg2017; @Seidenberg2020]. This is due to several factors including the range of phenomena related to its function as well as its enormous importance in public health, including education [@Castles2018; @Rayner2001; @Seidenberg2017]. Reading involves information processing over a variety of bases of knowledge and related perceptual mechanisms, including vision [@Reichle1998], phonological processing [@Harm1999; @Wagner1987], semantics [@Harm2004; @Siegelman2020], and language experience more broadly [@Seidenberg2018], among other knowledge domains. 

Computational modeling in the scientific enterprise of understanding reading, like other psychological sciences, has been an important part of developing robust theories of the mental processes involved. The computational bases of many of these perceptual and cognitive processes are understood in no small part due to the corresponding computational models that implement important aspects of such processes. Computational models are important for a variety of reasons, including introspecting about aspects of development of cognition that happen outside of conscious awareness, testing hypotheses about such processes, and doing so that allow for detailed investigations about the structure of the system that might not be possible in human or animal models. @Seidenberg2022 provides a summary of the dominant theorizing and a review of the relevant history.

Particular attention has been paid to the specific relationship between print and speech in reading development because of its irregular structure in some languages, especially English. This type of structure has come to be known as *quasiregular*, given the semi-systematic ways that letters and speech sounds relate [@Plaut1996; @Seidenberg1989]. Our understanding of information processing in knowledge domains involving quasiregular structure originates with an influential model of reading from @Seidenberg1989 (hereafter SM89), and extended in @Plaut1996. Additional discussion of quasiregularity and its impacts on learning and cognition can be found in @Seidenberg2014 and @Bybee2005, with a discussion of its implications on learning in educational contexts in @Seidenberg2020. Computational models of their processing derive from influential work by the PDP Research Group [@Rumelhart1986] on a variety of cognitive domains to which connectionist learning principles and their associated computational architectures were applied, supporting the emergence of connectionist architectures like SM89.

SM89 proposed a learning architecture using a multi-layer perceptron classifier that processed representations of words using representations of their features of print, speech, and semantics. Input layers represent bases of perception and action involved in reading words aloud. The artificial neural network processes input representations via weighted connections in interlevel ("hidden") layers, which allow for cooperative and competitive states of activation to take place across representational units of a given word.

Competing theories involve another perspective on how we compute the pronunciation of words of varying structural regularity: the dual-route theory [@Coltheart2005]. The core of this theory is that reading a word aloud must involve two different mechanisms. One of the routes computes a phonological output by assembling phonemes from their corresponding letters based on a set of symbolic rules designed to do so. The other accesses the word from a lexical storage location in cases where the rules aren't able to accomplish the task properly^[This second route actually contains two routes: one that references semantics and another that doesn't. The implemented model in @Coltheart2001 posits the additional semantic route (the "lexical semantic route") as an unimplemented portion of the model. The characterization of "dual routes" holds though because of the distinction between the "assembly" method by letter-sound rules and the lookup mechanism that happens via the other "lexical" route/ mechanism.]. This theory is implemented in corresponding computational models [@Coltheart2001; @Coltheart1993], including subsequent models that adhere to some of the theory's principles but extend them in novel ways [@Perry2010; @Perry2019]. These alternative computational models of reading came in the wake of SM89, and implement the dual-routes as two separate computational mechanisms.

The basic process of the original dual route computational models is as follows. When an input string is provided to the model it is processed over some number of cycles. Each cycle corresponds to a propagation of activation from one module to subsequent modules. This activation occurs across the two routes, thus competing to reach the output module first, with the faster route providing the output pronunciation.

## Models of multisyllabic word reading

The "connectionist dual-process" model described in @Perry2010 has the capacity to accommodate words of up to two syllables
The CDP++ model [@Perry2010] posits a complex architecture with subcomponents that capture different aspects of the theory from which the computational architecture is based. Said differently, their system lacks architectural homogeneity, a hallmark of connectionist learning systems. Some assumptions of the system violate primitives of learning seen in naturalistic environments. For example, CDP++ requires the prespecification of a graphemic level of representation, based on the assumption that letter sequences map cleanly onto phonemic sequences, and that such representational units contribute to low level operations within the reading system. Graphemes are identified on the input layer based on their frequency,  This violates an important aspect of development of word reading knowledge in that such representations (i.e., the ways that print sequences relate to auditory sequences) are learned and do not preexist in the learner once knowledge about print begins to develop.

In a connectionist architecture something like a grapheme may well exist, but it is an emergent aspect of the knowledge of the system that develops as the result of the exposure of the learning architecture to the environment.

The selection of representational units is a critical issue of theoretical interest in the development of a learning architecture that learns to read words. A fundamental question will always be: how do such representational units arise in learning? This issue plays even larger in models of word reading that deal in long words given that the longer the words are the more representational units there are to account for. In symbolic approaches this has been taken up historically as an issue of positing rules of identification, as in Rastle and Coltheart (2000). These rules take the form of complex verbal descriptions that specify structured labels for representational units based on the presence or absence of structural elements in a printed or spoken wordform.


## Statistical learning



# Survey of previous architectures

## Simple recurrent networks
The most comprehensive application of an SRN to date is Sibley et al. (2010), which used a two-component architecture for orthography and phonology, each with an SRN operating under the hood.

The most recent of these architectures can be found in @Luthra2020, which they refer to as VOISeR. This model of orthography-to-phonology processing takes in an orthographic sequence (a spatially represented)



## "Serial" effects in naming
The evidence most commonly taken to suggest that there is some type of serial processing operating during naming, particularly for words that contain "irregular" pronunciations, concerns the timecourse of naming processes for such words. 

Such findings are typically identified as evidence for a dual-route process operating during reading. The dual-route theory predicts that 


## Strategic control
There have been a number of studies concerning so-called "extra-stimulus" factors that concern processes in naming (see @Kello2003 for a review), which have been described broadly as strategies for cognitive control in word naming. The most important of these for the present work has to do with the time-course of processing printed words.

In behavioral research on aspects of control in word reading, the method of control is typically manipulated by providing special instructions to the participant, or constructing a paradigm to elicit a control-type mechanism when processing a visually presented word. Most research on this topic and using experimental paradigms along these lines has concerned short, or monosyllabic words. This isn't surprising given the rich history of such words in theories of word recognition (discussed elsewhere here), and that characteristics of the stimuli have driven theorizing and experimentation; monosyllabic words offer natural constraints to theory building that are useful to the endeavor, and provide simplifying case-studies of most critical characteristics observed in words more broadly (see @Yap2009 for discussion).


# Behavioral data
There are a number of possibilities for the visual span over which visual information is passed in the process of initiating phonology in word reading.



Earlier connectionist models avoided this issue in favor of simplified feedforward networks that typically passed visual information to phonology in a single temporal step. Alternative implementations using recurrent backpropagation through time were also used (ref.) These networks function with a continuous, recurrent component, over temporal intervals ("ticks" in that literature) where the input pattern (in a feedforward network) is allowed to stay clamped to the input layer, allowing for gradual buildup of the input signal over some time period. During training, error signal is backpropagated over timesteps where inputs are gradually being increased up to their eventual full activation state. However, architectures with recurrent backpropagation along these lines are simulating the timecourse of activation in a way that is different than networks that take time-distributed input patterns, like LSTM architectures and, more specifically, the architecture laid out in the current work.  Rather than simulating the ways that sequentially-arranged portions of perceptual information play in cross-modal mappings (where the perceptual information unfolds in a time-distributed manner), these earlier implementations of continuous processes that operate over some time were developed in order to understand the types of disordered behavior seen, for example, in patients with brain injuries that impact lexical or semantic processing (@Plaut1996, @Rogers2004). 

## The goal
The goal of this work is to incorporate time in a simple, cognitively plausible way into a limited model of English word naming (producing speech from print). In doing so the intent is to motivate a novel direction for the development of connectionist architectures that account for time distributed aspects of perceptual processes of human behavior such as, but not limited to, audition and vision. This will be accomplished through presenting details of the model architecture relevant to the development of such theories and their computational implementations alongside results that convey aspects of its behavior that lends legitimacy to the system. Several initial results are provided and discussed along with a number of results that point to important related phenomena in child development and their corresponding future directions related to this work.


