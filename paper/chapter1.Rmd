---
title: "introduction"
output: html_document
---

# Chapter 1: Introduction

Words are read by virtue of perceptual and cognitive processes that are distributed across space and time. As a reader engages visually with a word printed on the page, the reader's eyes move across portions of printed word, tapping her or his knowledge of speech, print, and meaning. Historically, cognitive accounts of word reading have been focused on the simplest of words of English - those with one syllable [@Perry2010; @Rastle2000; @Sibley2010; @Yap2009]. Models of monosyllabic word reading have been especially dominant in the connectionist learning literature (e.g., @Plaut1996; @Seidenberg1989), though preliminary implementations of recurrent networks that are capable of processing longer words have been put forward [@Sibley2008; @Sibley2010], but this work is young.

The focus on short words results from two primary factors. First, any model of word reading must at the very least account for the development of knowledge of the simplest words in the language given that short words tend to be learned earlier than long ones. Second, accounting for words that are longer than one syllable requires computational architecture that accounts for time-varying aspects of processing that occur over longer words, but can be avoided when studying shorter ones. This includes but is not limited to variability in prosodic information involved in pronunciation over different syllables (especially of vowels and their associated patterns of stress).

This dissertation reports on a model of word reading that associates print to speech, and that can accommodate words not bounded by orthographic or phonological length - that is, of words that are not limited to a single syllable. This model incorporates a number of standard assumptions about the characteristics of word reading^[These assumptions were adopted and extended from those articulated in @Plaut1996. See also the description of GRAIN networks in @McClelland1993 for related characteristics of similar information processing systems to this one.]:

* Learning happens over distributed representations of letters and sounds, where such representations convey featural information about their corresponding visual and articulatory structure
* Representational information comes to be encoded in patterns of activity on units in the system's architecture
* These patterns of activity encode graded knowledge about the elements of learning (words) and their myriad substructure
* Learning about visual and phonological features, and their covariation, happens gradually over the course of learning

Additionally, this work extends previous computational models of word reading by developing a model with the following characteristics:

1. Sequential dependencies within items (i.e., letters, sounds) are encoded by time-sensitive processes captured by the model.
2. Letters and sounds are represented veridically. Each letter and phoneme is represented with a representation that captures something about its unique (distributed) structure relative to all other letters and phonemes.
3. Knowledge about letters and phonemes are not bound by their slots within items during learning.
4. Learning that happens over the time-varying print and speech sequences are integrated within a single learning system, where activation within and across layers of the network is mutually constraining.

The remaining chapters of this dissertation are organized in the following way. First, in the remaining portion of Chapter 1, I will introduce the central issues in word reading as they relate to the type of sequential processing that is essential to the theory developed in the dissertation. Additionally, a brief history of models of word recognition will be provided. Chapter 2 describes the model architecture, highlighting the features that make it distinct from other previous architectures. Chapter 3 describes a range of human behavioral phenomena captured by the model, thus validating the architecture. Chapter 4 is a general discussion, addressing lingering issues with the model described and framing the dissertation in a broader theoretical landscape of human learning, and discussing future directions.

# Introduction
Language comes and goes in a time-contingent fashion. The language that we see and hear is structured in large part by sequential statistics that are learned through cognitive processes that happen across time. Letters are processed visually according to patterns of fixation that occur in a temporally governed manner, and auditory processes take place relative to sound patterns that appear in a fast fading way over time - among others. As a result, our theoretical models should account for the fact that such processing takes place in a sequentially arranged, time-contingent manner. Theories of reading are no exception given the range of temporal processes that operate in developing the skill.

Prevailing models of word reading have dealt with temporal aspects of processing in a few ways. Several influential models have used attractor networks that allow for a pattern of activation to settle into a stable state using recurrent dynamics [@Harm2004; @Plaut1996] when simulating learning and performance for monosyllabic words (mapping a spatially-fixed pattern of print to a spatially-fixed pattern of phonology). These models allow for the state of the system to change over time as a result of experience with a single learning event (like a word). The temporal dynamics and their effects under disorder have been important in understanding especially the results of injury to the cognitive system, where basins of attraction that develop through the recurrent dynamics of the system show behavior similar to brain-injured patients whose learning and performance they simulate (see @Plaut1991 for an example, and @Seidenberg2017 for a thorough discussion related to reading behavior).

In a related but underdeveloped line of work, simple recurrent networks (SRNs; see @Elman1990) have been applied to learning sequences involved in word reading [@Sibley2008; @Sibley2010]. In their most simple form when applied to word learning, simple recurrent networks allow for the encoding of variable length sequences (like printed or spoken words) into a fixed length pattern. This is made possible through a network that passes the elements of a given sequence through a time-varying network, where a single set of weighted connections encodes dependencies across the sequence, and in turn across all items that participate in training. The models in @Sibley2008 perform this task for letters and phonemes separately, where offline processing allows the output pattern for a given item of print to then be associated using a second SRN with a time-varying sequence of phonemes that corresponds to that print item. The model in @Sibley2010 extended the core idea and technical aspects of the architecture in @Sibley2008 in a single learning system. Similar to the model reported in this dissertation, the network in @Sibley2010 used recurrent layers for orthography and phonology within the same model, where the phonological SRN takes the fixed length representation and decodes it into a sequence of phonemes as output. While important aspects of the implementation aren't clear from the reporting on the model ^[For example, the featural representations for orthography aren't described, including whether or not padded/ justified representations were used. More needs to be known about the nature of an SRN-based approach to an orthography-phonology reading model in order to make a more full assessment of its viability and theoretical value. To this end, the work of this dissertation is intended to be an extension of the @Sibley2010 model.], the way that it incorporates temporal processing on orthography and phonology seems intuitive. Letters are processed sequentially. The sequence of letters for a given word are decomposed into a hidden state pattern and passed to another portion of the network that associates that pattern with the word's sequence of phonemes.

Second, some models have implemented a component of the architecture dedicated to stress [@Perry2010], which encodes information about temporal dimensions of words (like the primary-secondary stress pattern in the word `r scaps('thankful')`) when learning how the word's orthographic pattern maps in a spatial way to its corresponding phonological pattern. Third, a few models have used simple recurrent networks (e.g., @Sibley2010) to simulate the time-contingent learning associated with processing sequences (letters and phonemes). How time factors into word reading is typically discussed in the literature as concerning the processing of syllables: models of word reading can either deal with polysyllabic words or not. This distinction makes sense at one level, given that syllables are an important unit of speech. They carry information about vowel stress, and are an organizational category of language, contributing to the understanding of how consonants and vowels cluster within and across words. However, sequential statistics relevant to long words go beyond structure related to syllables. For example, orthotactic patterns exist as a matter of linguistic structure not strictly tied to syllabic structure.

In a separate research tradition, several architectures have been proposed in the engineering literature in order to simulate the relationship between text and speech for technological and commercial ends.

This dissertation introduces novel aspects of a computational architecture that incorporates temporal processing into the reading system, along with associated aspects of the architecture that allow for temporal dynamics not used or investigated in previous computational models of naming English.


# Models of word reading: A brief history

## Representational units

## Models of multisyllabic word reading

The "connectionist dual-process" model described in @Perry2010 has the capacity to accommodate words of up to two syllables
The CDP++ model [@Perry2010] posits a complex architecture with subcomponents that capture different aspects of the theory from which the computational architecture is based. Said differently, their system lacks architectural homogeneity, a hallmark of connectionist learning systems. Some assumptions of the system violate primitives of learning seen in naturalistic environments. For example, CDP++ requires the prespecification of a graphemic level of representation, based on the assumption that letter sequences map cleanly onto phonemic sequences, and that such representational units contribute to low level operations within the reading system. Graphemes are identified on the input layer based on their frequency,  This violates an important aspect of development of word reading knowledge in that such representations (i.e., the ways that print sequences relate to auditory sequences) are learned and do not preexist in the learner once knowledge about print begins to develop.

In a connectionist architecture something like a grapheme may well exist, but it is an emergent aspect of the knowledge of the system that develops as the result of the exposure of the learning architecture to the environment.

The selection of representational units is a critical issue of theoretical interest in the development of a learning architecture that learns to read words. A fundamental question will always be: how do such representational units arise in learning? This issue plays even larger in models of word reading that deal in long words given that the longer the words are the more representational units there are to account for. In symbolic approaches this has been taken up historically as an issue of positing rules of identification, as in Rastle and Coltheart (2000). These rules take the form of complex verbal descriptions that specify structured labels for representational units based on the presence or absence of structural elements in a printed or spoken wordform.


## Statistical learning



# Survey of previous architectures

## Simple recurrent networks
The most comprehensive application of an SRN to date is Sibley et al. (2010), which used a two-component architecture for orthography and phonology, each with an SRN operating under the hood.

The most recent of these architectures can be found in @Luthra2020, which they refer to as VOISeR. This model of orthography-to-phonology processing takes in an orthographic sequence (a spatially represented)



## "Serial" effects in naming
The evidence most commonly taken to suggest that there is some type of serial processing operating during naming, particularly for words that contain "irregular" pronunciations, concerns the timecourse of naming processes for such words. 

Such findings are typically identified as evidence for a dual-route process operating during reading. The dual-route theory predicts that 


## Strategic control
There have been a number of studies concerning so-called "extra-stimulus" factors that concern processes in naming (see @kello2003 for a review), which have been described broadly as strategies for cognitive control in word naming. The most important of these for the present work has to do with the time-course of processing printed words.

In behavioral research on aspects of control in word reading, the method of control is typically manipulated by providing special instructions to the participant, or constructing a paradigm to elicit a control-type mechanism when processing a visually presented word. Most research on this topic and using experimental paradigms along these lines has concerned short, or monosyllabic words. This isn't surprising given the rich history of such words in theories of word recognition (discussed elsewhere here), and that characteristics of the stimuli have driven theorizing and experimentation; monosyllabic words offer natural constraints to theory building that are useful to the endeavor, and provide simplifying case-studies of most critical characteristics observed in words more broadly (see @Yap2009 for discussion).


# Behavioral data
There are a number of possibilities for the visual span over which visual information is passed in the process of initiating phonology in word reading.



Earlier connectionist models avoided this issue in favor of simplified feedforward networks that typically passed visual information to phonology in a single temporal step. Alternative implementations using recurrent backpropagation through time were also used (ref.) These networks function with a continuous, recurrent component, over temporal intervals ("ticks" in that literature) where the input pattern (in a feedforward network) is allowed to stay clamped to the input layer, allowing for gradual buildup of the input signal over some time period. During training, error signal is backpropagated over timesteps where inputs are gradually being increased up to their eventual full activation state. However, architectures with recurrent backpropagation along these lines are simulating the timecourse of activation in a way that is different than networks that take time-distributed input patterns, like LSTM architectures and, more specifically, the architecture laid out in the current work.  Rather than simulating the ways that sequentially-arranged portions of perceptual information play in cross-modal mappings (where the perceptual information unfolds in a time-distributed manner), these earlier implementations of continuous processes that operate over some time were developed in order to understand the types of disordered behavior seen, for example, in patients with brain injuries that impact lexical or semantic processing (@Plaut1996, @Rogers2004). 

## The goal
The goal of this work is to incorporate time in a simple, cognitively plausible way into a limited model of English word naming (producing speech from print). In doing so the intent is to motivate a novel direction for the development of connectionist architectures that account for time distributed aspects of perceptual processes of human behavior such as, but not limited to, audition and vision. This will be accomplished through presenting details of the model architecture relevant to the development of such theories and their computational implementations alongside results that convey aspects of its behavior that lends legitimacy to the system. Several initial results are provided and discussed along with a number of results that point to important related phenomena in child development and their corresponding future directions related to this work.


